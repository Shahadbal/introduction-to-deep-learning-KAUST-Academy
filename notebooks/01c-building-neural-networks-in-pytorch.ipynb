{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkQC2iPIGZUO"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqXqSwkNMZnh"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, model_selection, pipeline, preprocessing\n",
        "import torch\n",
        "import torchmetrics\n",
        "from torch import nn, optim, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZWFwAtSMf2-"
      },
      "source": [
        "# Building Neural Networks in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sI9mlHKMi0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ7gP_USMul2"
      },
      "source": [
        "## Building a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si6PQ9vhMxP8"
      },
      "outputs": [],
      "source": [
        "prng = torch.manual_seed(42)\n",
        "m = 100\n",
        "features = [\n",
        "    torch.ones((m, 1)),\n",
        "    torch.normal(mean=1.0, std=1.0, size=(m, 1), generator=prng)\n",
        "]\n",
        "X = torch.cat(features, dim=1)\n",
        "error = torch.normal(mean=0.0, std=5e-1, size=(m, 1), generator=prng)\n",
        "beta = torch.tensor([[3.0], [1.5]])\n",
        "y = X @ beta + error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFl-qannNNQx"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 1], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Arb3VEomvR3u"
      },
      "outputs": [],
      "source": [
        "prng = torch.manual_seed(42)\n",
        "_dataset = utils.data.TensorDataset(X,  y)\n",
        "train_dataset, test_dataset = utils.data.random_split(_dataset, [80, 20], generator=prng)\n",
        "\n",
        "batch_size = 1\n",
        "train_dataloader = utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dataloader = utils.data.DataLoader(test_dataset, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZeA-5v8P82e"
      },
      "outputs": [],
      "source": [
        "# initialize weights\n",
        "prng = torch.manual_seed(1)\n",
        "weights = torch.randn((2, 1), generator=prng, requires_grad=True)\n",
        "\n",
        "\n",
        "def model_fn(X):\n",
        "    return X @ weights\n",
        "\n",
        "def loss_fn(y, y_hat):\n",
        "    return torch.sqrt(torch.mean((y - y_hat)**2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1izaWjUP_rJ"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 200\n",
        "log_epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for features, targets in train_dataloader:\n",
        "\n",
        "        # forward pass\n",
        "        predictions = model_fn(features)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * learning_rate\n",
        "            weights.grad.zero_()\n",
        "  \n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcFDpL30y99V"
      },
      "outputs": [],
      "source": [
        "print(f'Final Parameters: {weights[:, 0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xQbRLvFCnTr"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    total_loss = torch.zeros((1,1))\n",
        "    for features, target in test_dataloader:\n",
        "        predictions = model_fn(features)\n",
        "        loss = loss_fn(target, predictions)\n",
        "        total_loss += loss\n",
        "\n",
        "print(f\"Average test loss: {total_loss.item() / len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUxsbvw4TNg1"
      },
      "outputs": [],
      "source": [
        "_ = plt.plot(X[:, 1], y, 'o')\n",
        "_ = plt.xlabel(r\"$X_1$\", fontsize=15)\n",
        "_ = plt.ylabel(\"y\", fontsize=15, rotation=0)\n",
        "\n",
        "new_features = [\n",
        "    torch.ones((m, 1)),\n",
        "    torch.linspace(-2, 4, m).reshape((-1, 1))    \n",
        "]\n",
        "X_new = torch.cat(new_features, dim=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_new = model_fn(X_new)\n",
        "\n",
        "_ = plt.plot(X_new[:, 1], y_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ1dVpGmUvRt"
      },
      "source": [
        "## Model training usng torch.nn and torch.optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTHAqPuASKfk"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "input_size = 2\n",
        "output_size = 1\n",
        "model_fn = nn.Linear(input_size, output_size, bias=False)\n",
        "\n",
        "optimizer = torch.optim.SGD(model_fn.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hriDz8EeVGMW"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "log_epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for features, targets in train_dataloader:\n",
        "        \n",
        "        # forward pass\n",
        "        predictions = model_fn(features)        \n",
        "        loss = loss_fn(predictions, targets)\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()        \n",
        "        optimizer.step()        \n",
        "        optimizer.zero_grad()    \n",
        "\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hT9NfAqVosD"
      },
      "outputs": [],
      "source": [
        "print('Final Parameters:', model_fn.weight)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model_fn(X)"
      ],
      "metadata": {
        "id": "FbvwMyI31XIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aesY6uzLiOQZ"
      },
      "source": [
        "## Building multi-layer perceptrons for classification and regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSxSC-VgiV1U"
      },
      "source": [
        "### Breast Cancer Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU0jTdRUAqg5"
      },
      "outputs": [],
      "source": [
        "datasets.load_breast_cancer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVfwGGcAicBN"
      },
      "outputs": [],
      "source": [
        "features, targets = datasets.load_breast_cancer(return_X_y=True, as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZSaHYUjidCl"
      },
      "outputs": [],
      "source": [
        "features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJKUwvhvidhG"
      },
      "outputs": [],
      "source": [
        "features.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtWHqgefBsal"
      },
      "outputs": [],
      "source": [
        "random_state = np.random.RandomState(42)\n",
        "train_features, test_features, train_targets, test_targets = model_selection.train_test_split(\n",
        "    features,\n",
        "    targets,\n",
        "    test_size=0.1,\n",
        "    random_state=random_state,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzTJAisTASsT"
      },
      "outputs": [],
      "source": [
        "features_preprocessing_pipeline = pipeline.make_pipeline(\n",
        "    preprocessing.StandardScaler(),\n",
        "    preprocessing.FunctionTransformer(lambda X: X.astype(np.float32)),\n",
        "    preprocessing.FunctionTransformer(lambda X: torch.from_numpy(X)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaaGXqNuAS4k"
      },
      "outputs": [],
      "source": [
        "train_features_tensor = features_preprocessing_pipeline.fit_transform(train_features)\n",
        "train_targets_tensor = torch.from_numpy(train_targets.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygZL9vbUATD6"
      },
      "outputs": [],
      "source": [
        "train_dataset = utils.data.TensorDataset(train_features_tensor, train_targets_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = utils.data.DataLoader(train_dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "_, input_size = train_features_tensor.shape\n",
        "hidden_size = 100\n",
        "output_size = 2\n",
        "\n",
        "model_fn = nn.Sequential(\n",
        "    nn.Linear(input_size, hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_size, output_size),\n",
        "    nn.Softmax(dim=1)\n",
        ") \n",
        "\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(model_fn.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "hFMfo99B92eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdBQchCeCoTV"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "log_epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for features, targets in train_dataloader:\n",
        "        \n",
        "        # forward pass\n",
        "        predictions = model_fn(features)        \n",
        "        loss = loss_fn(predictions, targets)\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()        \n",
        "        optimizer.step()        \n",
        "        optimizer.zero_grad()    \n",
        "\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCCpbjXrKIH_"
      },
      "source": [
        "### Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz5I10uoFEij"
      },
      "outputs": [],
      "source": [
        "test_features_tensor = features_preprocessing_pipeline.transform(test_features)\n",
        "test_targets_tensor = torch.from_numpy(test_targets.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UO1VbZcGGaU"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model_fn(test_features_tensor)\n",
        "    predictions_tensor = logits.argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMRNL5e8GQpS"
      },
      "outputs": [],
      "source": [
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=output_size)\n",
        "accuracy(predictions_tensor, test_targets_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiGZS3AWKNL1"
      },
      "source": [
        "### Saving a PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZht3mtOKPb-"
      },
      "outputs": [],
      "source": [
        "RESULTS_DIR = pathlib.Path(\"./results\")\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "torch.save(model_fn, RESULTS_DIR / \"classifier.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agHnE83Gie-t"
      },
      "source": [
        "### Predicting house prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pic_KeQvHUR8"
      },
      "outputs": [],
      "source": [
        "datasets.fetch_california_housing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTfsl2JHUR8"
      },
      "outputs": [],
      "source": [
        "features, targets = datasets.fetch_california_housing(return_X_y=True, as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRKDrTgqHUR8"
      },
      "outputs": [],
      "source": [
        "features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzfG-j5DHUR9"
      },
      "outputs": [],
      "source": [
        "features.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.describe() # units are 100k USD"
      ],
      "metadata": {
        "id": "x4-uuq_fClPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmB1B6ykHUR9"
      },
      "outputs": [],
      "source": [
        "random_state = np.random.RandomState(42)\n",
        "train_features, test_features, train_targets, test_targets = model_selection.train_test_split(\n",
        "    features,\n",
        "    targets,\n",
        "    test_size=0.1,\n",
        "    random_state=random_state,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUeWX4jBHUR9"
      },
      "outputs": [],
      "source": [
        "features_preprocessing_pipeline = pipeline.make_pipeline(\n",
        "    preprocessing.StandardScaler(),\n",
        "    preprocessing.FunctionTransformer(lambda X: X.astype(np.float32)),\n",
        "    preprocessing.FunctionTransformer(lambda X: torch.from_numpy(X)),\n",
        ")\n",
        "\n",
        "targets_preprocessing_pipeline = pipeline.make_pipeline(\n",
        "    preprocessing.FunctionTransformer(lambda X: X.to_numpy()),\n",
        "    preprocessing.FunctionTransformer(lambda X: X.reshape(-1, 1)),    \n",
        "    preprocessing.FunctionTransformer(lambda X: X.astype(np.float32)),\n",
        "    preprocessing.FunctionTransformer(lambda X: torch.from_numpy(X)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N60DLvaFHUR-"
      },
      "outputs": [],
      "source": [
        "train_features_tensor = features_preprocessing_pipeline.fit_transform(train_features)\n",
        "train_targets_tensor = targets_preprocessing_pipeline.fit_transform(train_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9sAUxuqHUR-"
      },
      "outputs": [],
      "source": [
        "train_dataset = utils.data.TensorDataset(train_features_tensor, train_targets_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataloader = utils.data.DataLoader(train_dataset, batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329CnQnEHUR-"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "_, input_size = train_features_tensor.shape\n",
        "hidden_sizes = [100, 100, 100]\n",
        "output_size = 1\n",
        "\n",
        "modules = []\n",
        "for hidden_size in hidden_sizes:\n",
        "    module = nn.Linear(input_size, hidden_size)\n",
        "    modules.append(module)\n",
        "    modules.append(nn.ReLU())\n",
        "    input_size = hidden_size\n",
        "modules.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "model_fn = nn.Sequential(\n",
        "    *modules\n",
        ")\n",
        "\n",
        "learning_rate = 1e-2\n",
        "optimizer = torch.optim.SGD(model_fn.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-GTpqaTHUR-"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "log_epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for features, targets in train_dataloader:\n",
        "        \n",
        "        # forward pass\n",
        "        predictions = model_fn(features)        \n",
        "        loss = loss_fn(predictions, targets)\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()        \n",
        "        optimizer.step()        \n",
        "        optimizer.zero_grad()    \n",
        "\n",
        "    if epoch % log_epochs == 0:\n",
        "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    predictions_tensor = model_fn(train_features_tensor)\n",
        "\n",
        "training_loss = loss_fn(predictions_tensor, train_targets_tensor)\n",
        "print(f\"Training loss: {torch.sqrt(training_loss) * 100_000} USD\")"
      ],
      "metadata": {
        "id": "xhHdqI8TB3Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m2lVjJcHUR_"
      },
      "outputs": [],
      "source": [
        "test_features_tensor = features_preprocessing_pipeline.transform(test_features)\n",
        "test_targets_tensor = targets_preprocessing_pipeline.transform(test_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNHrKRGYHUR_"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    predictions_tensor = model_fn(test_features_tensor)\n",
        "\n",
        "test_loss = loss_fn(predictions_tensor, test_targets_tensor)\n",
        "print(f\"Test loss: {torch.sqrt(test_loss) * 100_000} USD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zA8eIy57o-Db"
      },
      "outputs": [],
      "source": [
        "torch.save(model_fn, RESULTS_DIR / \"regressor.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqj37ufbG2nP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}